[
  {
    "id": "arxiv-2602.01002v1",
    "title": "How RLHF Amplifies Sycophancy",
    "authors": "Itai Shapira, Gerdus Benade, Ariel D. Procaccia",
    "source": "arXiv",
    "date": "2026-02-01",
    "link": "http://arxiv.org/abs/2602.01002v1",
    "summary": "[AI 摘要] Large language models often exhibit increased sycophantic behavior after preference-based post-training, showing a stronger tendency to affirm a user'...",
    "tags": [
      "AI+Security"
    ]
  },
  {
    "id": "arxiv-2602.00997v1",
    "title": "Error Taxonomy-Guided Prompt Optimization",
    "authors": "Mayank Singh, Vikas Yadav, Eduardo Blanco",
    "source": "arXiv",
    "date": "2026-02-01",
    "link": "http://arxiv.org/abs/2602.00997v1",
    "summary": "[AI 摘要] Automatic Prompt Optimization (APO) is a powerful approach for extracting performance from large language models without modifying their weights. Many...",
    "tags": [
      "AI+Security"
    ]
  },
  {
    "id": "arxiv-2602.00996v1",
    "title": "DeALOG: Decentralized Multi-Agents Log-Mediated Reasoning Framework",
    "authors": "Abhijit Chakraborty, Ashish Raj Shekhar, Shiven Agarwal et al.",
    "source": "arXiv",
    "date": "2026-02-01",
    "link": "http://arxiv.org/abs/2602.00996v1",
    "summary": "[AI 摘要] Complex question answering across text, tables and images requires integrating diverse information sources. A framework supporting specialized process...",
    "tags": [
      "AI+Security"
    ]
  },
  {
    "id": "arxiv-2602.00994v1",
    "title": "Reasoning and Tool-use Compete in Agentic RL:From Quantifying Interference to Disentangled Tuning",
    "authors": "Yu Li, Mingyang Yi, Xiuyu Li et al.",
    "source": "arXiv",
    "date": "2026-02-01",
    "link": "http://arxiv.org/abs/2602.00994v1",
    "summary": "[AI 摘要] Agentic Reinforcement Learning (ARL) focuses on training large language models (LLMs) to interleave reasoning with external tool execution to solve co...",
    "tags": [
      "AI+Security"
    ]
  },
  {
    "id": "arxiv-2602.00991v1",
    "title": "Tripartite quantum steering in Schwarzschild spacetime",
    "authors": "Guang-Wei Mi, Xiaofen Huang, Tinggui Zhang",
    "source": "arXiv",
    "date": "2026-02-01",
    "link": "http://arxiv.org/abs/2602.00991v1",
    "summary": "[AI 摘要] We investigate the effects of Hawking radiation on quantum steering and steering asymmetry in a tripartite system embedded in Schwarzschild spacetime....",
    "tags": [
      "Arch/Hardware"
    ]
  },
  {
    "id": "arxiv-2602.00983v1",
    "title": "DISPO: Enhancing Training Efficiency and Stability in Reinforcement Learning for Large Language Model Mathematical Reasoning",
    "authors": "Batuhan K. Karaman, Aditya Rawal, Suhaila Shakiah et al.",
    "source": "arXiv",
    "date": "2026-02-01",
    "link": "http://arxiv.org/abs/2602.00983v1",
    "summary": "[AI 摘要] Reinforcement learning with verifiable rewards has emerged as a promising paradigm for enhancing the reasoning capabilities of large language models p...",
    "tags": [
      "AI+Security"
    ]
  },
  {
    "id": "arxiv-2602.00982v1",
    "title": "Navigating Simply, Aligning Deeply: Winning Solutions for Mouse vs. AI 2025",
    "authors": "Phu-Hoa Pham, Chi-Nguyen Tran, Dao Sy Duy Minh et al.",
    "source": "arXiv",
    "date": "2026-02-01",
    "link": "http://arxiv.org/abs/2602.00982v1",
    "summary": "[AI 摘要] Visual robustness and neural alignment remain critical challenges in developing artificial agents that can match biological vision systems. We present...",
    "tags": [
      "AI+Security"
    ]
  },
  {
    "id": "arxiv-2602.00981v1",
    "title": "MedSpeak: A Knowledge Graph-Aided ASR Error Correction Framework for Spoken Medical QA",
    "authors": "Yutong Song, Shiva Shrestha, Chenhan Lyu et al.",
    "source": "arXiv",
    "date": "2026-02-01",
    "link": "http://arxiv.org/abs/2602.00981v1",
    "summary": "[AI 摘要] Spoken question-answering (SQA) systems relying on automatic speech recognition (ASR) often struggle with accurately recognizing medical terminology. ...",
    "tags": [
      "AI+Security"
    ]
  },
  {
    "id": "arxiv-2602.00979v1",
    "title": "GradingAttack: Attacking Large Language Models Towards Short Answer Grading Ability",
    "authors": "Xueyi Li, Zhuoneng Zhou, Zitao Liu et al.",
    "source": "arXiv",
    "date": "2026-02-01",
    "link": "http://arxiv.org/abs/2602.00979v1",
    "summary": "[AI 摘要] Large language models (LLMs) have demonstrated remarkable potential for automatic short answer grading (ASAG), significantly boosting student assessme...",
    "tags": [
      "AI+Security"
    ]
  },
  {
    "id": "arxiv-2602.00955v1",
    "title": "Spectral moments of Bures-Hall ensemble and applications to entanglement entropy",
    "authors": "Linfeng Wei, Youyi Huang, Lu Wei",
    "source": "arXiv",
    "date": "2026-02-01",
    "link": "http://arxiv.org/abs/2602.00955v1",
    "summary": "[AI 摘要] We study spectral moments of the Bures-Hall random matrices ensemble. The main result establishes a recurrence relation for the $k$-th spectral moment...",
    "tags": [
      "Arch/Hardware"
    ]
  },
  {
    "id": "arxiv-2602.00954v1",
    "title": "Small-Margin Preferences Still Matter-If You Train Them Right",
    "authors": "Jinlong Pang, Zhaowei Zhu, Na Di et al.",
    "source": "arXiv",
    "date": "2026-02-01",
    "link": "http://arxiv.org/abs/2602.00954v1",
    "summary": "[AI 摘要] Preference optimization methods such as DPO align large language models (LLMs) using paired comparisons, but their effectiveness can be highly sensiti...",
    "tags": [
      "AI+Security"
    ]
  },
  {
    "id": "arxiv-2602.00950v1",
    "title": "MindGuard: Guardrail Classifiers for Multi-Turn Mental Health Support",
    "authors": "António Farinhas, Nuno M. Guerreiro, José Pombal et al.",
    "source": "arXiv",
    "date": "2026-02-01",
    "link": "http://arxiv.org/abs/2602.00950v1",
    "summary": "[AI 摘要] Large language models are increasingly used for mental health support, yet their conversational coherence alone does not ensure clinical appropriatene...",
    "tags": [
      "AI+Security"
    ]
  },
  {
    "id": "arxiv-2602.00948v1",
    "title": "FinEvo: From Isolated Backtests to Ecological Market Games for Multi-Agent Financial Strategy Evolution",
    "authors": "Mingxi Zou, Jiaxiang Chen, Aotian Luo et al.",
    "source": "arXiv",
    "date": "2026-02-01",
    "link": "http://arxiv.org/abs/2602.00948v1",
    "summary": "[AI 摘要] Conventional financial strategy evaluation relies on isolated backtests in static environments. Such evaluations assess each policy independently, ove...",
    "tags": [
      "AI+Security"
    ]
  },
  {
    "id": "arxiv-2602.00945v1",
    "title": "Neural FOXP2 -- Language Specific Neuron Steering for Targeted Language Improvement in LLMs",
    "authors": "Anusa Saha, Tanmay Joshi, Vinija Jain et al.",
    "source": "arXiv",
    "date": "2026-02-01",
    "link": "http://arxiv.org/abs/2602.00945v1",
    "summary": "[AI 摘要] LLMs are multilingual by training, yet their lingua franca is often English, reflecting English language dominance in pretraining. Other languages rem...",
    "tags": [
      "AI+Security"
    ]
  },
  {
    "id": "arxiv-2602.00933v1",
    "title": "MCP-Atlas: A Large-Scale Benchmark for Tool-Use Competency with Real MCP Servers",
    "authors": "Chaithanya Bandi, Ben Hertzberg, Geobio Boo et al.",
    "source": "arXiv",
    "date": "2026-01-31",
    "link": "http://arxiv.org/abs/2602.00933v1",
    "summary": "[AI 摘要] The Model Context Protocol (MCP) is rapidly becoming the standard interface for Large Language Models (LLMs) to discover and invoke external tools. Ho...",
    "tags": [
      "AI+Security"
    ]
  },
  {
    "id": "arxiv-2602.00931v1",
    "title": "Continuous-Utility Direct Preference Optimization",
    "authors": "Muhammad Ahmed Mohsin, Muhammad Umer, Ahsan Bilal et al.",
    "source": "arXiv",
    "date": "2026-01-31",
    "link": "http://arxiv.org/abs/2602.00931v1",
    "summary": "[AI 摘要] Large language model reasoning is often treated as a monolithic capability, relying on binary preference supervision that fails to capture partial pro...",
    "tags": [
      "AI+Security"
    ]
  },
  {
    "id": "arxiv-2602.00929v1",
    "title": "Learning Abstractions for Hierarchical Planning in Program-Synthesis Agents",
    "authors": "Zergham Ahmed, Kazuki Irie, Joshua B. Tenenbaum et al.",
    "source": "arXiv",
    "date": "2026-01-31",
    "link": "http://arxiv.org/abs/2602.00929v1",
    "summary": "[AI 摘要] Humans learn abstractions and use them to plan efficiently to quickly generalize across tasks -- an ability that remains challenging for state-of-the-...",
    "tags": [
      "AI+Security"
    ]
  },
  {
    "id": "arxiv-2602.00928v1",
    "title": "Electro-optic conversion of itinerant Fock states",
    "authors": "Thomas Werner, Erfan Riyazi, Samarth Hawaldar et al.",
    "source": "arXiv",
    "date": "2026-01-31",
    "link": "http://arxiv.org/abs/2602.00928v1",
    "summary": "[AI 摘要] Superconducting qubits are a leading candidate for utility-scale quantum computing due to their fast gate speeds and steadily decreasing error rates. ...",
    "tags": [
      "Arch/Hardware"
    ]
  },
  {
    "id": "arxiv-2602.00916v1",
    "title": "Noise Resilient 1SDIQKD for Practical Quantum Networks",
    "authors": "Syed M Arslan, Muhammad T Rahim, Asad Ali et al.",
    "source": "arXiv",
    "date": "2026-01-31",
    "link": "http://arxiv.org/abs/2602.00916v1",
    "summary": "[AI 摘要] One-sided device-independent quantum key distribution (1SDI-QKD) offers a practical middle ground between fully device-independent protocols and stand...",
    "tags": [
      "Arch/Hardware"
    ]
  },
  {
    "id": "arxiv-2602.00913v1",
    "title": "Do Schwartz Higher-Order Values Help Sentence-Level Human Value Detection? When Hard Gating Hurts",
    "authors": "Víctor Yeste, Paolo Rosso",
    "source": "arXiv",
    "date": "2026-01-31",
    "link": "http://arxiv.org/abs/2602.00913v1",
    "summary": "[AI 摘要] Sentence-level human value detection is typically framed as multi-label classification over Schwartz values, but it remains unclear whether Schwartz h...",
    "tags": [
      "AI+Security"
    ]
  },
  {
    "id": "arxiv-2602.00911v1",
    "title": "Synapse Compendium Aware Federated Knowledge Exchange for Tool Routed LLMs",
    "authors": "Abhijit Chakraborty, Sandipan De, Yash Shah et al.",
    "source": "arXiv",
    "date": "2026-01-31",
    "link": "http://arxiv.org/abs/2602.00911v1",
    "summary": "[AI 摘要] Collaborative learning among LLM-based agents under federated learning faces challenges, including communication costs, heterogeneity in data, and too...",
    "tags": [
      "AI+Security"
    ]
  },
  {
    "id": "arxiv-2602.00906v1",
    "title": "Hallucination is a Consequence of Space-Optimality: A Rate-Distortion Theorem for Membership Testing",
    "authors": "Anxin Guo, Jingwei Li",
    "source": "arXiv",
    "date": "2026-01-31",
    "link": "http://arxiv.org/abs/2602.00906v1",
    "summary": "[AI 摘要] Large language models often hallucinate with high confidence on \"random facts\" that lack inferable patterns. We formalize the memorization of such fac...",
    "tags": [
      "AI+Security"
    ]
  },
  {
    "id": "arxiv-2602.00900v1",
    "title": "Asymmetry and dynamical criticality",
    "authors": "Andesson B. Nascimento, Lucas Chibebe Céleri",
    "source": "arXiv",
    "date": "2026-01-31",
    "link": "http://arxiv.org/abs/2602.00900v1",
    "summary": "[AI 摘要] Symmetries play a central role in both equilibrium and nonequilibrium phase transitions, yet their quantitative characterization in dynamical quantum ...",
    "tags": [
      "Arch/Hardware"
    ]
  },
  {
    "id": "arxiv-2602.00891v1",
    "title": "Universal Quantum Birthmark: Ghost of the quantum past",
    "authors": "Ivy Xiaoya, Anton M. Graf, Eric J. Heller et al.",
    "source": "arXiv",
    "date": "2026-01-31",
    "link": "http://arxiv.org/abs/2602.00891v1",
    "summary": "[AI 摘要] Quantum dynamics retains a permanent and universal memory of its initial conditions, even in systems whose spectra display fully chaotic, random-matri...",
    "tags": [
      "Arch/Hardware"
    ]
  },
  {
    "id": "arxiv-2602.00887v1",
    "title": "EffGen: Enabling Small Language Models as Capable Autonomous Agents",
    "authors": "Gaurav Srivastava, Aafiya Hussain, Chi Wang et al.",
    "source": "arXiv",
    "date": "2026-01-31",
    "link": "http://arxiv.org/abs/2602.00887v1",
    "summary": "[AI 摘要] Most existing language model agentic systems today are built and optimized for large language models (e.g., GPT, Claude, Gemini) via API calls. While ...",
    "tags": [
      "AI+Security"
    ]
  },
  {
    "id": "arxiv-2602.00874v1",
    "title": "Sublinear Time Quantum Algorithm for Attention Approximation",
    "authors": "Zhao Song, Jianfei Xue, Jiahao Zhang et al.",
    "source": "arXiv",
    "date": "2026-01-31",
    "link": "http://arxiv.org/abs/2602.00874v1",
    "summary": "[AI 摘要] Given the query, key and value matrices $Q, K, V\\in \\mathbb{R}^{n\\times d}$, the attention module is defined as $\\mathrm{Att}(Q, K, V)=D^{-1}AV$ where...",
    "tags": [
      "AI+Security",
      "Arch/Hardware"
    ]
  },
  {
    "id": "arxiv-2602.00871v1",
    "title": "Beyond Output Critique: Self-Correction via Task Distillation",
    "authors": "Hossein A. Rahmani, Mengting Wan, Pei Zhou et al.",
    "source": "arXiv",
    "date": "2026-01-31",
    "link": "http://arxiv.org/abs/2602.00871v1",
    "summary": "[AI 摘要] Large language models (LLMs) have shown promising self-correction abilities, where iterative refinement improves the quality of generated responses. H...",
    "tags": [
      "AI+Security"
    ]
  },
  {
    "id": "arxiv-2602.00856v1",
    "title": "Higher-order transformations of bidirectional quantum processes",
    "authors": "Luca Apadula, Alessandro Bisio, Giulio Chiribella et al.",
    "source": "arXiv",
    "date": "2026-01-31",
    "link": "http://arxiv.org/abs/2602.00856v1",
    "summary": "[AI 摘要] Bidirectional devices are devices for which the roles of the input and output ports can be exchanged. Mathematically, these devices are described by b...",
    "tags": [
      "Arch/Hardware"
    ]
  },
  {
    "id": "arxiv-2602.00851v1",
    "title": "Persuasion Propagation in LLM Agents",
    "authors": "Hyejun Jeong, Amir Houmansadr, Shlomo Zilberstein et al.",
    "source": "arXiv",
    "date": "2026-01-31",
    "link": "http://arxiv.org/abs/2602.00851v1",
    "summary": "[AI 摘要] Modern AI agents increasingly combine conversational interaction with autonomous task execution, such as coding and web research, raising a natural qu...",
    "tags": [
      "AI+Security"
    ]
  },
  {
    "id": "arxiv-2602.00848v1",
    "title": "Factuality on Demand: Controlling the Factuality-Informativeness Trade-off in Text Generation",
    "authors": "Ziwei Gong, Yanda Chen, Julia Hirschberg et al.",
    "source": "arXiv",
    "date": "2026-01-31",
    "link": "http://arxiv.org/abs/2602.00848v1",
    "summary": "[AI 摘要] Large language models (LLMs) encode knowledge with varying degrees of confidence. When responding to queries, models face an inherent trade-off: they ...",
    "tags": [
      "AI+Security"
    ]
  },
  {
    "id": "arxiv-2602.00840v1",
    "title": "Code Quality Analysis of Translations from C to Rust",
    "authors": "Biruk Tadesse, Vikram Nitin, Mazin Salah et al.",
    "source": "arXiv",
    "date": "2026-01-31",
    "link": "http://arxiv.org/abs/2602.00840v1",
    "summary": "[AI 摘要] C/C++ is a prevalent programming language. Yet, it suffers from significant memory and thread-safety issues. Recent studies have explored automated tr...",
    "tags": [
      "AI+Security"
    ]
  },
  {
    "id": "arxiv-2602.00838v1",
    "title": "Exploration of Unary Arithmetic-Based Matrix Multiply Units for Low Precision DL Accelerators",
    "authors": "Prabhu Vellaisamy, Harideep Nair, Di Wu et al.",
    "source": "arXiv",
    "date": "2026-01-31",
    "link": "http://arxiv.org/abs/2602.00838v1",
    "summary": "[AI 摘要] General matrix multiplication (GEMM) is a fundamental operation in deep learning (DL). With DL moving increasingly toward low precision, recent works ...",
    "tags": [
      "AI+Security",
      "Arch/Hardware"
    ]
  },
  {
    "id": "arxiv-2602.00815v1",
    "title": "Resource-Efficient Reinforcement for Reasoning Large Language Models via Dynamic One-Shot Policy Refinement",
    "authors": "Yunjian Zhang, Sudong Wang, Yang Li et al.",
    "source": "arXiv",
    "date": "2026-01-31",
    "link": "http://arxiv.org/abs/2602.00815v1",
    "summary": "[AI 摘要] Large language models (LLMs) have exhibited remarkable performance on complex reasoning tasks, with reinforcement learning under verifiable rewards (R...",
    "tags": [
      "AI+Security"
    ]
  },
  {
    "id": "arxiv-2602.00811v1",
    "title": "MissMAC-Bench: Building Solid Benchmark for Missing Modality Issue in Robust Multimodal Affective Computing",
    "authors": "Ronghao Lin, Honghao Lu, Ruixing Wu et al.",
    "source": "arXiv",
    "date": "2026-01-31",
    "link": "http://arxiv.org/abs/2602.00811v1",
    "summary": "[AI 摘要] As a knowledge discovery task over heterogeneous data sources, current Multimodal Affective Computing (MAC) heavily rely on the completeness of multip...",
    "tags": [
      "AI+Security"
    ]
  },
  {
    "id": "arxiv-2602.00803v1",
    "title": "AutoGNN: End-to-End Hardware-Driven Graph Preprocessing for Enhanced GNN Performance",
    "authors": "Seungkwan Kang, Seungjun Lee, Donghyun Gouk et al.",
    "source": "arXiv",
    "date": "2026-01-31",
    "link": "http://arxiv.org/abs/2602.00803v1",
    "summary": "[AI 摘要] Graph neural network (GNN) inference faces significant bottlenecks in preprocessing, which often dominate overall inference latency. We introduce Auto...",
    "tags": [
      "Arch/Hardware"
    ]
  },
  {
    "id": "arxiv-2602.00800v1",
    "title": "JTok: On Token Embedding as another Axis of Scaling Law via Joint Token Self-modulation",
    "authors": "Yebin Yang, Huaijin Wu, Fu Guo et al.",
    "source": "arXiv",
    "date": "2026-01-31",
    "link": "http://arxiv.org/abs/2602.00800v1",
    "summary": "[AI 摘要] LLMs have traditionally scaled along dense dimensions, where performance is coupled with near-linear increases in computational cost. While MoE decoup...",
    "tags": [
      "AI+Security"
    ]
  },
  {
    "id": "arxiv-2602.00785v1",
    "title": "World Models as an Intermediary between Agents and the Real World",
    "authors": "Sherry Yang",
    "source": "arXiv",
    "date": "2026-01-31",
    "link": "http://arxiv.org/abs/2602.00785v1",
    "summary": "[AI 摘要] Large language model (LLM) agents trained using reinforcement learning has achieved superhuman performance in low-cost environments like games, mathem...",
    "tags": [
      "AI+Security"
    ]
  },
  {
    "id": "arxiv-2602.00783v1",
    "title": "Analysis of Hessian Scaling for Local and Global Costs in Variational Quantum Algorithm",
    "authors": "Yihan Huang, Yangshuai Wang",
    "source": "arXiv",
    "date": "2026-01-31",
    "link": "http://arxiv.org/abs/2602.00783v1",
    "summary": "[AI 摘要] Barren plateaus are typically characterized by vanishing gradients, yet the feasibility of curvature-based optimization fundamentally relies on the st...",
    "tags": [
      "Arch/Hardware"
    ]
  },
  {
    "id": "arxiv-2602.00769v1",
    "title": "Eliciting Trustworthiness Priors of Large Language Models via Economic Games",
    "authors": "Siyu Yan, Lusha Zhu, Jian-Qiao Zhu",
    "source": "arXiv",
    "date": "2026-01-31",
    "link": "http://arxiv.org/abs/2602.00769v1",
    "summary": "[AI 摘要] One critical aspect of building human-centered, trustworthy artificial intelligence (AI) systems is maintaining calibrated trust: appropriate reliance...",
    "tags": [
      "AI+Security"
    ]
  },
  {
    "id": "arxiv-2602.00759v1",
    "title": "Adaptive Ability Decomposing for Unlocking Large Reasoning Model Effective Reinforcement Learning",
    "authors": "Zhipeng Chen, Xiaobo Qin, Wayne Xin Zhao et al.",
    "source": "arXiv",
    "date": "2026-01-31",
    "link": "http://arxiv.org/abs/2602.00759v1",
    "summary": "[AI 摘要] Reinforcement learning with verifiable rewards (RLVR) has shown great potential to enhance the reasoning ability of large language models (LLMs). Howe...",
    "tags": [
      "AI+Security"
    ]
  },
  {
    "id": "arxiv-2602.00757v1",
    "title": "ScratchEval : A Multimodal Evaluation Framework for LLMs in Block-Based Programming",
    "authors": "Yuan Si, Simeng Han, Daming Li et al.",
    "source": "arXiv",
    "date": "2026-01-31",
    "link": "http://arxiv.org/abs/2602.00757v1",
    "summary": "[AI 摘要] LLMs have achieved strong performance on text-based programming tasks, yet they remain unreliable for block-based languages such as Scratch. Scratch p...",
    "tags": [
      "AI+Security"
    ]
  },
  {
    "id": "arxiv-2602.00755v1",
    "title": "Evolving Interpretable Constitutions for Multi-Agent Simulation",
    "authors": "Ujwal Kumar, Alice Saito, Hershraj Niranjani et al.",
    "source": "arXiv",
    "date": "2026-01-31",
    "link": "http://arxiv.org/abs/2602.00755v1",
    "summary": "[AI 摘要] Constitutional AI has focused on single-model alignment using fixed principles. However, multi-agent systems create novel alignment challenges through...",
    "tags": [
      "AI+Security"
    ]
  },
  {
    "id": "arxiv-2602.00750v1",
    "title": "Bypassing Prompt Injection Detectors through Evasive Injections",
    "authors": "Md Jahedur Rahman, Ihsen Alouani",
    "source": "arXiv",
    "date": "2026-01-31",
    "link": "http://arxiv.org/abs/2602.00750v1",
    "summary": "[AI 摘要] Large language models (LLMs) are increasingly used in interactive and retrieval-augmented systems, but they remain vulnerable to task drift; deviation...",
    "tags": [
      "AI+Security"
    ]
  },
  {
    "id": "arxiv-2602.00748v1",
    "title": "HyperOffload: Graph-Driven Hierarchical Memory Management for Large Language Models on SuperNode Architectures",
    "authors": "Fangxin Liu, Qinghua Zhang, Hanjing Shen et al.",
    "source": "arXiv",
    "date": "2026-01-31",
    "link": "http://arxiv.org/abs/2602.00748v1",
    "summary": "[AI 摘要] The rapid evolution of Large Language Models (LLMs) towards long-context reasoning and sparse architectures has pushed memory requirements far beyond ...",
    "tags": [
      "AI+Security"
    ]
  },
  {
    "id": "arxiv-2602.00747v1",
    "title": "Decouple Searching from Training: Scaling Data Mixing via Model Merging for Large Language Model Pre-training",
    "authors": "Shengrui Li, Fei Zhao, Kaiyan Zhao et al.",
    "source": "arXiv",
    "date": "2026-01-31",
    "link": "http://arxiv.org/abs/2602.00747v1",
    "summary": "[AI 摘要] Determining an effective data mixture is a key factor in Large Language Model (LLM) pre-training, where models must balance general competence with pr...",
    "tags": [
      "AI+Security"
    ]
  },
  {
    "id": "arxiv-2602.00746v1",
    "title": "Can Vision-Language Models Handle Long-Context Code? An Empirical Study on Visual Compression",
    "authors": "Jianping Zhong, Guochang Li, Chen Zhi et al.",
    "source": "arXiv",
    "date": "2026-01-31",
    "link": "http://arxiv.org/abs/2602.00746v1",
    "summary": "[AI 摘要] Large Language Models (LLMs) struggle with long-context code due to window limitations. Existing textual code compression methods mitigate this via se...",
    "tags": [
      "AI+Security"
    ]
  },
  {
    "id": "arxiv-2602.00745v1",
    "title": "Energy Absorption Interferometry",
    "authors": "Stafford Withington, Willem Jellema",
    "source": "arXiv",
    "date": "2026-01-31",
    "link": "http://arxiv.org/abs/2602.00745v1",
    "summary": "[AI 摘要] Energy Absorption Interferometry (EAI) is a technique for measuring the responsivities and complex-valued spatial polarimetric forms of the individual...",
    "tags": [
      "Arch/Hardware"
    ]
  },
  {
    "id": "arxiv-2602.00743v1",
    "title": "SA-VLA: Spatially-Aware Flow-Matching for Vision-Language-Action Reinforcement Learning",
    "authors": "Xu Pan, Zhenglin Wan, Xingrui Yu et al.",
    "source": "arXiv",
    "date": "2026-01-31",
    "link": "http://arxiv.org/abs/2602.00743v1",
    "summary": "[AI 摘要] Vision-Language-Action (VLA) models exhibit strong generalization in robotic manipulation, yet reinforcement learning (RL) fine-tuning often degrades ...",
    "tags": [
      "AI+Security"
    ]
  },
  {
    "id": "arxiv-2602.00740v1",
    "title": "ExperienceWeaver: Optimizing Small-sample Experience Learning for LLM-based Clinical Text Improvement",
    "authors": "Ziyan Xiao, Yinghao Zhu, Liang Peng et al.",
    "source": "arXiv",
    "date": "2026-01-31",
    "link": "http://arxiv.org/abs/2602.00740v1",
    "summary": "[AI 摘要] Clinical text improvement is vital for healthcare efficiency but remains difficult due to limited high-quality data and the complex constraints of med...",
    "tags": [
      "AI+Security"
    ]
  },
  {
    "id": "arxiv-2602.00726v1",
    "title": "Augmenting Clinical Decision-Making with an Interactive and Interpretable AI Copilot: A Real-World User Study with Clinicians in Nephrology and Obstetrics",
    "authors": "Yinghao Zhu, Dehao Sui, Zixiang Wang et al.",
    "source": "arXiv",
    "date": "2026-01-31",
    "link": "http://arxiv.org/abs/2602.00726v1",
    "summary": "[AI 摘要] Clinician skepticism toward opaque AI hinders adoption in high-stakes healthcare. We present AICare, an interactive and interpretable AI copilot for c...",
    "tags": [
      "AI+Security"
    ]
  }
]