[
  {
    "id": "arxiv-2602.06963v1",
    "title": "Charge-$4e$ superconductor with parafermionic vortices: A path to universal topological quantum computation",
    "authors": "Zhengyan Darius Shi, Zhaoyu Han, Srinivas Raghu et al.",
    "source": "arXiv",
    "date": "2026-02-06",
    "link": "http://arxiv.org/abs/2602.06963v1",
    "summary": "[AI 摘要] Topological superconductors (TSCs) provide a promising route to fault-tolerant quantum information processing. However, the canonical Majorana platfor...",
    "tags": [
      "Arch/Hardware"
    ]
  },
  {
    "id": "arxiv-2602.06964v1",
    "title": "Learning a Generative Meta-Model of LLM Activations",
    "authors": "Grace Luo, Jiahai Feng, Trevor Darrell et al.",
    "source": "arXiv",
    "date": "2026-02-06",
    "link": "http://arxiv.org/abs/2602.06964v1",
    "summary": "[AI 摘要] Existing approaches for analyzing neural network activations, such as PCA and sparse autoencoders, rely on strong structural assumptions. Generative m...",
    "tags": [
      "AI+Security"
    ]
  },
  {
    "id": "arxiv-2602.06948v1",
    "title": "Agentic Uncertainty Reveals Agentic Overconfidence",
    "authors": "Jean Kaddour, Srijan Patel, Gbètondji Dovonon et al.",
    "source": "arXiv",
    "date": "2026-02-06",
    "link": "http://arxiv.org/abs/2602.06948v1",
    "summary": "[AI 摘要] Can AI agents predict whether they will succeed at a task? We study agentic uncertainty by eliciting success probability estimates before, during, and...",
    "tags": [
      "AI+Security"
    ]
  },
  {
    "id": "arxiv-2602.06941v1",
    "title": "Endogenous Resistance to Activation Steering in Language Models",
    "authors": "Alex McKenzie, Keenan Pepper, Stijn Servaes et al.",
    "source": "arXiv",
    "date": "2026-02-06",
    "link": "http://arxiv.org/abs/2602.06941v1",
    "summary": "[AI 摘要] Large language models can resist task-misaligned activation steering during inference, sometimes recovering mid-generation to produce improved respons...",
    "tags": [
      "AI+Security"
    ]
  },
  {
    "id": "arxiv-2602.06939v1",
    "title": "Cochain Perspectives on Temporal-Difference Signals for Learning Beyond Markov Dynamics",
    "authors": "Zuyuan Zhang, Sizhe Tang, Tian Lan",
    "source": "arXiv",
    "date": "2026-02-06",
    "link": "http://arxiv.org/abs/2602.06939v1",
    "summary": "[AI 摘要] Non-Markovian dynamics are commonly found in real-world environments due to long-range dependencies, partial observability, and memory effects. The Be...",
    "tags": [
      "AI+Security"
    ]
  },
  {
    "id": "arxiv-2602.06920v1",
    "title": "Halluverse-M^3: A multitask multilingual benchmark for hallucination in LLMs",
    "authors": "Samir Abdaljalil, Parichit Sharma, Erchin Serpedin et al.",
    "source": "arXiv",
    "date": "2026-02-06",
    "link": "http://arxiv.org/abs/2602.06920v1",
    "summary": "[AI 摘要] Hallucinations in large language models remain a persistent challenge, particularly in multilingual and generative settings where factual consistency ...",
    "tags": [
      "AI+Security"
    ]
  },
  {
    "id": "arxiv-2602.06913v1",
    "title": "Symmetry and localisation in causally constrained quantum operator dynamics",
    "authors": "Marcell D. Kovács, Christopher J. Turner, Lluís Masanes",
    "source": "arXiv",
    "date": "2026-02-06",
    "link": "http://arxiv.org/abs/2602.06913v1",
    "summary": "[AI 摘要] This paper explores the connection between causality and many-body dynamics by studying the algebraic structure of tri-partite unitaries ('walls') whi...",
    "tags": [
      "Arch/Hardware"
    ]
  },
  {
    "id": "arxiv-2602.06911v1",
    "title": "TamperBench: Systematically Stress-Testing LLM Safety Under Fine-Tuning and Tampering",
    "authors": "Saad Hossain, Tom Tseng, Punya Syon Pandey et al.",
    "source": "arXiv",
    "date": "2026-02-06",
    "link": "http://arxiv.org/abs/2602.06911v1",
    "summary": "[AI 摘要] As increasingly capable open-weight large language models (LLMs) are deployed, improving their tamper resistance against unsafe modifications, whether...",
    "tags": [
      "AI+Security"
    ]
  },
  {
    "id": "arxiv-2602.06887v1",
    "title": "Plato's Form: Toward Backdoor Defense-as-a-Service for LLMs with Prototype Representations",
    "authors": "Chen Chen, Yuchen Sun, Jiaxin Gao et al.",
    "source": "arXiv",
    "date": "2026-02-06",
    "link": "http://arxiv.org/abs/2602.06887v1",
    "summary": "[AI 摘要] Large language models (LLMs) are increasingly deployed in security-sensitive applications, yet remain vulnerable to backdoor attacks. However, existin...",
    "tags": [
      "AI+Security"
    ]
  },
  {
    "id": "arxiv-2602.06875v1",
    "title": "TraceCoder: A Trace-Driven Multi-Agent Framework for Automated Debugging of LLM-Generated Code",
    "authors": "Jiangping Huang, Wenguang Ye, Weisong Sun et al.",
    "source": "arXiv",
    "date": "2026-02-06",
    "link": "http://arxiv.org/abs/2602.06875v1",
    "summary": "[AI 摘要] Large Language Models (LLMs) often generate code with subtle but critical bugs, especially for complex tasks. Existing automated repair methods typica...",
    "tags": [
      "AI+Security"
    ]
  },
  {
    "id": "arxiv-2602.06855v1",
    "title": "AIRS-Bench: a Suite of Tasks for Frontier AI Research Science Agents",
    "authors": "Alisia Lupidi, Bhavul Gauri, Thomas Simon Foster et al.",
    "source": "arXiv",
    "date": "2026-02-06",
    "link": "http://arxiv.org/abs/2602.06855v1",
    "summary": "[AI 摘要] LLM agents hold significant promise for advancing scientific research. To accelerate this progress, we introduce AIRS-Bench (the AI Research Science B...",
    "tags": [
      "AI+Security"
    ]
  },
  {
    "id": "arxiv-2602.06852v1",
    "title": "The Quantum Sieve Tracer: A Hybrid Framework for Layer-Wise Activation Tracing in Large Language Models",
    "authors": "Jonathan Pan",
    "source": "arXiv",
    "date": "2026-02-06",
    "link": "http://arxiv.org/abs/2602.06852v1",
    "summary": "[AI 摘要] Mechanistic interpretability aims to reverse-engineer the internal computations of Large Language Models (LLMs), yet separating sparse semantic signal...",
    "tags": [
      "AI+Security",
      "Arch/Hardware"
    ]
  },
  {
    "id": "arxiv-2602.06847v1",
    "title": "Consensus Protocols for Entanglement-Aware Scheduling in Distributed Quantum Neural Networks",
    "authors": "Kuan-Cheng Chen, Samuel Yen-Chi Chen, Mahdi Chehimi et al.",
    "source": "arXiv",
    "date": "2026-02-06",
    "link": "http://arxiv.org/abs/2602.06847v1",
    "summary": "[AI 摘要] The realization of distributed quantum neural networks (DQNNs) over quantum internet infrastructures faces fundamental challenges arising from the fra...",
    "tags": [
      "Arch/Hardware"
    ]
  },
  {
    "id": "arxiv-2602.06845v1",
    "title": "Comment on \"Relativistic covariance and nonlinear quantum mechanics: Tomonaga-Schwinger analysis''",
    "authors": "Lajos Diósi",
    "source": "arXiv",
    "date": "2026-02-06",
    "link": "http://arxiv.org/abs/2602.06845v1",
    "summary": "[AI 摘要] Contrary to the central claim (Hsu, 2026) published in Physics Letters B, the Tomonaga--Schwinger equation remains covariant despite the nonlinear mod...",
    "tags": [
      "Arch/Hardware"
    ]
  },
  {
    "id": "arxiv-2602.06841v1",
    "title": "From Features to Actions: Explainability in Traditional and Agentic AI Systems",
    "authors": "Sindhuja Chaduvula, Jessee Ho, Kina Kim et al.",
    "source": "arXiv",
    "date": "2026-02-06",
    "link": "http://arxiv.org/abs/2602.06841v1",
    "summary": "[AI 摘要] Over the last decade, explainable AI has primarily focused on interpreting individual model predictions, producing post-hoc explanations that relate i...",
    "tags": [
      "AI+Security"
    ]
  },
  {
    "id": "arxiv-2602.06838v1",
    "title": "An Adaptive Differentially Private Federated Learning Framework with Bi-level Optimization",
    "authors": "Jin Wang, Hui Ma, Fei Xing et al.",
    "source": "arXiv",
    "date": "2026-02-06",
    "link": "http://arxiv.org/abs/2602.06838v1",
    "summary": "[AI 摘要] Federated learning enables collaborative model training across distributed clients while preserving data privacy. However, in practical deployments, d...",
    "tags": [
      "AI+Security"
    ]
  },
  {
    "id": "arxiv-2602.06836v1",
    "title": "LLM Active Alignment: A Nash Equilibrium Perspective",
    "authors": "Tonghan Wang, Yuqi Pan, Xinyi Yang et al.",
    "source": "arXiv",
    "date": "2026-02-06",
    "link": "http://arxiv.org/abs/2602.06836v1",
    "summary": "[AI 摘要] We develop a game-theoretic framework for predicting and steering the behavior of populations of large language models (LLMs) through Nash equilibrium...",
    "tags": [
      "AI+Security"
    ]
  },
  {
    "id": "arxiv-2602.06823v1",
    "title": "AI-Generated Music Detection in Broadcast Monitoring",
    "authors": "David Lopez-Ayala, Asier Cabello, Pablo Zinemanas et al.",
    "source": "arXiv",
    "date": "2026-02-06",
    "link": "http://arxiv.org/abs/2602.06823v1",
    "summary": "[AI 摘要] AI music generators have advanced to the point where their outputs are often indistinguishable from human compositions. While detection methods have e...",
    "tags": [
      "AI+Security"
    ]
  },
  {
    "id": "arxiv-2602.06822v1",
    "title": "POP: Online Structural Pruning Enables Efficient Inference of Large Foundation Models",
    "authors": "Yi Chen, Wonjin Shin, Shuhong Liu et al.",
    "source": "arXiv",
    "date": "2026-02-06",
    "link": "http://arxiv.org/abs/2602.06822v1",
    "summary": "[AI 摘要] Large foundation models (LFMs) achieve strong performance through scaling, yet current structural pruning methods derive fixed pruning decisions durin...",
    "tags": [
      "AI+Security"
    ]
  },
  {
    "id": "arxiv-2602.06819v1",
    "title": "Bridging 6G IoT and AI: LLM-Based Efficient Approach for Physical Layer's Optimization Tasks",
    "authors": "Ahsan Mehmood, Naveed Ul Hassan, Ghassan M. Kraidy",
    "source": "arXiv",
    "date": "2026-02-06",
    "link": "http://arxiv.org/abs/2602.06819v1",
    "summary": "[AI 摘要] This paper investigates the role of large language models (LLMs) in sixth-generation (6G) Internet of Things (IoT) networks and proposes a prompt-engi...",
    "tags": [
      "AI+Security"
    ]
  },
  {
    "id": "arxiv-2602.06818v1",
    "title": "Wild Guesses and Mild Guesses in Active Concept Learning",
    "authors": "Anirudh Chari, Neil Pattanaik",
    "source": "arXiv",
    "date": "2026-02-06",
    "link": "http://arxiv.org/abs/2602.06818v1",
    "summary": "[AI 摘要] Human concept learning is typically active: learners choose which instances to query or test in order to reduce uncertainty about an underlying rule o...",
    "tags": [
      "AI+Security"
    ]
  },
  {
    "id": "arxiv-2602.06812v1",
    "title": "Hybrid Coupling Topology with Dynamic ZZ Suppression for Optimizing Circuit Depth during Runtime in Superconducting Quantum Processor",
    "authors": "Uday Sannigrahi, Amlan Chakrabarti, Swapnil Saha et al.",
    "source": "arXiv",
    "date": "2026-02-06",
    "link": "http://arxiv.org/abs/2602.06812v1",
    "summary": "[AI 摘要] To reduce circuit depth when executing Quantum algorithms, it is necessary to maximize qubit connectivity on a near-term quantum processor. While addr...",
    "tags": [
      "Arch/Hardware"
    ]
  },
  {
    "id": "arxiv-2602.06801v1",
    "title": "On the Identifiability of Steering Vectors in Large Language Models",
    "authors": "Sohan Venkatesh, Ashish Mahendran Kurapath",
    "source": "arXiv",
    "date": "2026-02-06",
    "link": "http://arxiv.org/abs/2602.06801v1",
    "summary": "[AI 摘要] Activation steering methods, such as persona vectors, are widely used to control large language model behavior and increasingly interpreted as reveali...",
    "tags": [
      "AI+Security"
    ]
  },
  {
    "id": "arxiv-2602.06796v1",
    "title": "Phase-sensitive characterization of a quantum frequency converter by spectral interferometry",
    "authors": "Mateusz J Olszewski, Kasper Hecht Alexander, Michael T M Woodley et al.",
    "source": "arXiv",
    "date": "2026-02-06",
    "link": "http://arxiv.org/abs/2602.06796v1",
    "summary": "[AI 摘要] We introduce an experimental technique for complete phase-sensitive characterization of arbitrary unitary spectral-temporal transformations of optical...",
    "tags": [
      "Arch/Hardware"
    ]
  },
  {
    "id": "arxiv-2602.06795v1",
    "title": "Generating Data-Driven Reasoning Rubrics for Domain-Adaptive Reward Modeling",
    "authors": "Kate Sanders, Nathaniel Weir, Sapana Chaudhary et al.",
    "source": "arXiv",
    "date": "2026-02-06",
    "link": "http://arxiv.org/abs/2602.06795v1",
    "summary": "[AI 摘要] An impediment to using Large Language Models (LLMs) for reasoning output verification is that LLMs struggle to reliably identify errors in thinking tr...",
    "tags": [
      "AI+Security"
    ]
  },
  {
    "id": "arxiv-2602.06790v1",
    "title": "Heralding efficiency and brightness optimization of a micro-ring resonator via tunable coupling",
    "authors": "Nathan Moses, Marcus J. Clark, Alex S. Clark et al.",
    "source": "arXiv",
    "date": "2026-02-06",
    "link": "http://arxiv.org/abs/2602.06790v1",
    "summary": "[AI 摘要] Efficient and bright single photon sources on photonic chips are key to scaling quantum technologies. Spontaneous four wave mixing in micro-ring reson...",
    "tags": [
      "Arch/Hardware"
    ]
  },
  {
    "id": "arxiv-2602.06777v1",
    "title": "Next-generation cyberattack detection with large language models: anomaly analysis across heterogeneous logs",
    "authors": "Yassine Chagna, Antal Goldschmidt",
    "source": "arXiv",
    "date": "2026-02-06",
    "link": "http://arxiv.org/abs/2602.06777v1",
    "summary": "[AI 摘要] This project explores large language models (LLMs) for anomaly detection across heterogeneous log sources. Traditional intrusion detection systems suf...",
    "tags": [
      "AI+Security"
    ]
  },
  {
    "id": "arxiv-2602.06771v1",
    "title": "AEGIS: Adversarial Target-Guided Retention-Data-Free Robust Concept Erasure from Diffusion Models",
    "authors": "Fengpeng Li, Kemou Li, Qizhou Wang et al.",
    "source": "arXiv",
    "date": "2026-02-06",
    "link": "http://arxiv.org/abs/2602.06771v1",
    "summary": "[AI 摘要] Concept erasure helps stop diffusion models (DMs) from generating harmful content; but current methods face robustness retention trade off. Robustness...",
    "tags": [
      "AI+Security"
    ]
  },
  {
    "id": "arxiv-2602.06762v1",
    "title": "Quasiperiodic dynamics in the nondipole x-ray strong field ionization in stabilization regime",
    "authors": "Aleksandr V. Boitsov, Karen Z. Hatsagortsyan, Christoph H. Keitel",
    "source": "arXiv",
    "date": "2026-02-06",
    "link": "http://arxiv.org/abs/2602.06762v1",
    "summary": "[AI 摘要] Recent advances in strong x-ray laser techniques enable the study of nonlinear multiphoton ionization in extreme high-frequency fields. Although the s...",
    "tags": [
      "Arch/Hardware"
    ]
  },
  {
    "id": "arxiv-2602.06759v1",
    "title": "\"Tab, Tab, Bug'': Security Pitfalls of Next Edit Suggestions in AI-Integrated IDEs",
    "authors": "Yunlong Lyu, Yixuan Tang, Peng Chen et al.",
    "source": "arXiv",
    "date": "2026-02-06",
    "link": "http://arxiv.org/abs/2602.06759v1",
    "summary": "[AI 摘要] Modern AI-integrated IDEs are shifting from passive code completion to proactive Next Edit Suggestions (NES). Unlike traditional autocompletion, NES i...",
    "tags": [
      "AI+Security"
    ]
  },
  {
    "id": "arxiv-2602.06756v1",
    "title": "$f$-Differential Privacy Filters: Validity and Approximate Solutions",
    "authors": "Long Tran, Antti Koskela, Ossi Räisä et al.",
    "source": "arXiv",
    "date": "2026-02-06",
    "link": "http://arxiv.org/abs/2602.06756v1",
    "summary": "[AI 摘要] Accounting for privacy loss under fully adaptive composition -- where both the choice of mechanisms and their privacy parameters may depend on the ent...",
    "tags": [
      "AI+Security"
    ]
  },
  {
    "id": "arxiv-2602.06754v1",
    "title": "A Unified Framework for LLM Watermarks",
    "authors": "Thibaud Gloaguen, Robin Staab, Nikola Jovanović et al.",
    "source": "arXiv",
    "date": "2026-02-06",
    "link": "http://arxiv.org/abs/2602.06754v1",
    "summary": "[AI 摘要] LLM watermarks allow tracing AI-generated texts by inserting a detectable signal into their generated content. Recent works have proposed a wide range...",
    "tags": [
      "AI+Security"
    ]
  },
  {
    "id": "arxiv-2602.06751v1",
    "title": "Beyond Function-Level Analysis: Context-Aware Reasoning for Inter-Procedural Vulnerability Detection",
    "authors": "Yikun Li, Ting Zhang, Jieke Shi et al.",
    "source": "arXiv",
    "date": "2026-02-06",
    "link": "http://arxiv.org/abs/2602.06751v1",
    "summary": "[AI 摘要] Recent progress in ML and LLMs has improved vulnerability detection, and recent datasets have reduced label noise and unrelated code changes. However,...",
    "tags": [
      "AI+Security"
    ]
  },
  {
    "id": "arxiv-2602.06744v1",
    "title": "Bridging Quantum and Semi-Classical Thermodynamics in Cavity QED",
    "authors": "Marcelo Janovitch, Sander Stammbach, Matteo Brunelli et al.",
    "source": "arXiv",
    "date": "2026-02-06",
    "link": "http://arxiv.org/abs/2602.06744v1",
    "summary": "[AI 摘要] In cavity quantum electrodynamics (QED), photons leaving the cavity can be irreversibly lost or reused as a power source. This dichotomy is reflected ...",
    "tags": [
      "Arch/Hardware"
    ]
  },
  {
    "id": "arxiv-2602.06718v1",
    "title": "GhostCite: A Large-Scale Analysis of Citation Validity in the Age of Large Language Models",
    "authors": "Zuyao Xu, Yuqi Qiu, Lu Sun et al.",
    "source": "arXiv",
    "date": "2026-02-06",
    "link": "http://arxiv.org/abs/2602.06718v1",
    "summary": "[AI 摘要] Citations provide the basis for trusting scientific claims; when they are invalid or fabricated, this trust collapses. With the advent of Large Langua...",
    "tags": [
      "AI+Security"
    ]
  },
  {
    "id": "arxiv-2602.06716v1",
    "title": "Geometry of restricted information: the case of quantum thermodynamics",
    "authors": "Tiago Pernambuco, Lucas Chibebe Céleri",
    "source": "arXiv",
    "date": "2026-02-06",
    "link": "http://arxiv.org/abs/2602.06716v1",
    "summary": "[AI 摘要] We formulate a geometric framework in which physical laws emerge from restricted access to microscopic information. Measurement constraints are modele...",
    "tags": [
      "Arch/Hardware"
    ]
  },
  {
    "id": "arxiv-2602.06709v1",
    "title": "Using Large Language Models to Support Automation of Failure Management in CI/CD Pipelines: A Case Study in SAP HANA",
    "authors": "Duong Bui, Stefan Grintz, Alexander Berndt et al.",
    "source": "arXiv",
    "date": "2026-02-06",
    "link": "http://arxiv.org/abs/2602.06709v1",
    "summary": "[AI 摘要] CI/CD pipeline failure management is time-consuming when performed manually. Automating this process is non-trivial because the information required f...",
    "tags": [
      "AI+Security"
    ]
  },
  {
    "id": "arxiv-2602.06700v1",
    "title": "Taipan: A Query-free Transfer-based Multiple Sensitive Attribute Inference Attack Solely from Publicly Released Graphs",
    "authors": "Ying Song, Balaji Palanisamy",
    "source": "arXiv",
    "date": "2026-02-06",
    "link": "http://arxiv.org/abs/2602.06700v1",
    "summary": "[AI 摘要] Graph-structured data underpin a wide spectrum of modern applications. However, complex graph topologies and homophilic patterns can facilitate attrib...",
    "tags": [
      "AI+Security"
    ]
  },
  {
    "id": "arxiv-2602.06699v1",
    "title": "Quantum Attention by Overlap Interference: Predicting Sequences from Classical and Many-Body Quantum Data",
    "authors": "Alessio Pecilli, Matteo Rosati",
    "source": "arXiv",
    "date": "2026-02-06",
    "link": "http://arxiv.org/abs/2602.06699v1",
    "summary": "[AI 摘要] We propose a variational quantum implementation of self-attention (QSA), the core operation in transformers and large language models, which predicts ...",
    "tags": [
      "AI+Security",
      "Arch/Hardware"
    ]
  },
  {
    "id": "arxiv-2602.06687v1",
    "title": "Evaluating and Enhancing the Vulnerability Reasoning Capabilities of Large Language Models",
    "authors": "Li Lu, Yanjie Zhao, Hongzhou Rao et al.",
    "source": "arXiv",
    "date": "2026-02-06",
    "link": "http://arxiv.org/abs/2602.06687v1",
    "summary": "[AI 摘要] Large Language Models (LLMs) have demonstrated remarkable proficiency in vulnerability detection. However, a critical reliability gap persists: models...",
    "tags": [
      "AI+Security"
    ]
  },
  {
    "id": "arxiv-2602.06671v1",
    "title": "Code vs Serialized AST Inputs for LLM-Based Code Summarization: An Empirical Study",
    "authors": "Shijia Dong, Haoruo Zhao, Paul Harvey",
    "source": "arXiv",
    "date": "2026-02-06",
    "link": "http://arxiv.org/abs/2602.06671v1",
    "summary": "[AI 摘要] Summarizing source code into natural language descriptions (code summarization) helps developers better understand program functionality and reduce th...",
    "tags": [
      "AI+Security"
    ]
  },
  {
    "id": "arxiv-2602.06669v1",
    "title": "compar:IA: The French Government's LLM arena to collect French-language human prompts and preference data",
    "authors": "Lucie Termignon, Simonas Zilinskas, Hadrien Pélissier et al.",
    "source": "arXiv",
    "date": "2026-02-06",
    "link": "http://arxiv.org/abs/2602.06669v1",
    "summary": "[AI 摘要] Large Language Models (LLMs) often show reduced performance, cultural alignment, and safety robustness in non-English languages, partly because Englis...",
    "tags": [
      "AI+Security"
    ]
  },
  {
    "id": "arxiv-2602.06665v1",
    "title": "Not All Layers Need Tuning: Selective Layer Restoration Recovers Diversity",
    "authors": "Bowen Zhang, Meiyi Wang, Harold Soh",
    "source": "arXiv",
    "date": "2026-02-06",
    "link": "http://arxiv.org/abs/2602.06665v1",
    "summary": "[AI 摘要] Post-training improves instruction-following and helpfulness of large language models (LLMs) but often reduces generation diversity, which leads to re...",
    "tags": [
      "AI+Security"
    ]
  },
  {
    "id": "arxiv-2602.06657v1",
    "title": "Second law of thermodynamics in closed quantum many-body systems",
    "authors": "Yuuya Chiba, Yasushi Yoneta, Ryusuke Hamazaki et al.",
    "source": "arXiv",
    "date": "2026-02-06",
    "link": "http://arxiv.org/abs/2602.06657v1",
    "summary": "[AI 摘要] The second law of thermodynamics for adiabatic operations -- constraints on state transitions in closed systems under external control -- is one of th...",
    "tags": [
      "Arch/Hardware"
    ]
  },
  {
    "id": "arxiv-2602.06655v1",
    "title": "Wonderboom -- Efficient, and Censorship-Resilient Signature Aggregation for Million Scale Consensus",
    "authors": "Zeta Avarikioti, Ray Neiheiser, Krzysztof Pietrzak et al.",
    "source": "arXiv",
    "date": "2026-02-06",
    "link": "http://arxiv.org/abs/2602.06655v1",
    "summary": "[AI 摘要] Over the last years, Ethereum has evolved into a public platform that safeguards the savings of hundreds of millions of people and secures more than $...",
    "tags": [
      "AI+Security"
    ]
  },
  {
    "id": "arxiv-2602.06652v1",
    "title": "Same Answer, Different Representations: Hidden instability in VLMs",
    "authors": "Farooq Ahmad Wani, Alessandro Suglia, Rohit Saxena et al.",
    "source": "arXiv",
    "date": "2026-02-06",
    "link": "http://arxiv.org/abs/2602.06652v1",
    "summary": "[AI 摘要] The robustness of Vision Language Models (VLMs) is commonly assessed through output-level invariance, implicitly assuming that stable predictions refl...",
    "tags": [
      "AI+Security"
    ]
  },
  {
    "id": "arxiv-2602.06644v1",
    "title": "A Complete Equational Theory for Real-Clifford+CH Quantum Circuits",
    "authors": "Alexandre Clément",
    "source": "arXiv",
    "date": "2026-02-06",
    "link": "http://arxiv.org/abs/2602.06644v1",
    "summary": "[AI 摘要] We introduce a complete equational theory for the fragment of quantum circuits generated by the real Clifford gates plus the two-qubit controlled-Hada...",
    "tags": [
      "Arch/Hardware"
    ]
  },
  {
    "id": "arxiv-2602.06638v1",
    "title": "Temperature Scaling Attack Disrupting Model Confidence in Federated Learning",
    "authors": "Kichang Lee, Jaeho Jin, JaeYeon Park et al.",
    "source": "arXiv",
    "date": "2026-02-06",
    "link": "http://arxiv.org/abs/2602.06638v1",
    "summary": "[AI 摘要] Predictive confidence serves as a foundational control signal in mission-critical systems, directly governing risk-aware logic such as escalation, abs...",
    "tags": [
      "AI+Security"
    ]
  },
  {
    "id": "arxiv-2602.06632v1",
    "title": "Normal mode splitting induced synchronization blockade in coupled quantum van der Pol oscillators",
    "authors": "Nissi Thomas, M. Senthilvelan",
    "source": "arXiv",
    "date": "2026-02-06",
    "link": "http://arxiv.org/abs/2602.06632v1",
    "summary": "[AI 摘要] We report a normal-mode induced synchronization blockade in coupled quantum van der Pol oscillators under the influence of external drive. In this mec...",
    "tags": [
      "Arch/Hardware"
    ]
  },
  {
    "id": "arxiv-2602.06630v1",
    "title": "TrapSuffix: Proactive Defense Against Adversarial Suffixes in Jailbreaking",
    "authors": "Mengyao Du, Han Fang, Haokai Ma et al.",
    "source": "arXiv",
    "date": "2026-02-06",
    "link": "http://arxiv.org/abs/2602.06630v1",
    "summary": "[AI 摘要] Suffix-based jailbreak attacks append an adversarial suffix, i.e., a short token sequence, to steer aligned LLMs into unsafe outputs. Since suffixes a...",
    "tags": [
      "AI+Security"
    ]
  }
]